# QAChatbot
ğŸ“„ PDF Question Answering Chatbot (LangChain + HuggingFace + Gradio)
This project is a local PDF-based Question Answering (QA) chatbot built with:

LangChain â€“ for document loading, splitting, embeddings, and retrieval

HuggingFace Hub â€“ for LLMs and embeddings

FAISS â€“ for local vector storage and fast similarity search

Gradio â€“ for a simple web-based interface

It allows you to upload a PDF, process it into vector embeddings, and ask natural language questions about the document.

ğŸš€ Features
Upload any PDF and process it into searchable text chunks.

Store embeddings locally using FAISS.

Retrieve the most relevant chunks for your query.

Answer questions using a HuggingFace LLM (e.g., google/flan-t5-large).

Simple and interactive Gradio UI.

ğŸ“¦ Installation
1ï¸âƒ£ Clone this repository
bash
Copy
Edit
git clone https://github.com/yourusername/pdf-qa-chatbot.git
cd pdf-qa-chatbot
2ï¸âƒ£ Install dependencies
bash
Copy
Edit
pip install langchain langchain-community gradio faiss-cpu sentence-transformers pypdf
ğŸ”‘ API Key Setup
Youâ€™ll need a HuggingFace API token to access the model.

Get your token from: https://huggingface.co/settings/tokens

Add it to your environment:

bash
Copy
Edit
export HUGGINGFACEHUB_API_TOKEN="your_token_here"
Or replace in code:

python
Copy
Edit
HUGGINGFACEHUB_API_TOKEN = "your_token_here"
âš™ï¸ Configuration
You can change the LLM and embedding models in the script:

python
Copy
Edit
LLM_MODEL_NAME = "google/flan-t5-large"
EMBEDDING_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
â–¶ï¸ Usage
Run the script:

bash
Copy
Edit
python app.py
Open your browser at http://127.0.0.1:7860.

ğŸ’» How It Works
PDF Upload â€“ Loads and extracts text from the uploaded PDF using PyPDFLoader.

Text Splitting â€“ Splits text into overlapping chunks with RecursiveCharacterTextSplitter.

Embeddings â€“ Creates vector embeddings with HuggingFaceEmbeddings.

FAISS Index â€“ Stores embeddings locally for fast retrieval.

Question Answering â€“ Uses RetrievalQA to fetch relevant chunks and pass them to the HuggingFace LLM.

Gradio Interface â€“ Handles PDF upload, processing, and answering questions.

ğŸ–¼ Example
Upload: sample.pdf

Ask: "What is the main topic of this document?"

Answer: The chatbot will return a concise answer based on the PDF content.

ğŸ“Œ Notes
For large PDFs, processing time may be longer.

You can swap the LLM with other HuggingFace models (e.g., mistralai/Mistral-7B-Instruct-v0.2).

This runs fully locally except for HuggingFace API calls.

ğŸ“œ License
MIT License â€“ feel free to use and modify.
